import pandas as pd
import requests
import shutil
import os
from pathlib import Path
from datetime import datetime
from tqdm import tqdm

# ==========================================
# [Phase 1] Universe Definition + Auto Conflict Resolution
# ==========================================
BASE_DIR = Path(__file__).resolve().parent.parent
MASTER_PATH = BASE_DIR / "data" / "bronze" / "master_ticker_list.csv"
BACKUP_PATH = BASE_DIR / "data" / "bronze" / "master_ticker_list_backup.csv"

# ì €ì¥ì†Œ ìœ„ì¹˜ ì •ì˜
YAHOO_DIR = BASE_DIR / "data" / "bronze" / "yahoo_price_data"
KAGGLE_DIR = BASE_DIR / "data" / "bronze" / "daily_prices" # Kaggle legacy

# SEC ë° NASDAQ ì†ŒìŠ¤
SEC_HEADERS = {'User-Agent': 'Individual_Researcher my_email@example.com'}
SEC_URL = "https://www.sec.gov/files/company_tickers.json"
NASDAQ_URL = "ftp://ftp.nasdaqtrader.com/SymbolDirectory/nasdaqtraded.txt"

def normalize_ticker(ticker):
    return str(ticker).strip().upper().replace(".", "-")

def get_new_tickers_from_web():
    """ì›¹ì—ì„œ ìµœì‹  ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘"""
    found_tickers = set()
    print("  ğŸ“¡ ì‹ ê·œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì¤‘ (SEC/NASDAQ)...")
    try:
        resp = requests.get(SEC_URL, headers=SEC_HEADERS, timeout=5)
        if resp.status_code == 200:
            df = pd.DataFrame.from_dict(resp.json(), orient='index')
            found_tickers.update(df['ticker'].apply(normalize_ticker).tolist())
    except: pass

    try:
        df = pd.read_csv(NASDAQ_URL, sep="|")
        ts = df[df['Test Issue'] == 'N']['Symbol'].dropna().apply(normalize_ticker).tolist()
        found_tickers.update(ts)
    except: pass
        
    return found_tickers

def scan_and_resolve_conflicts():
    """
    [í•µì‹¬ ë¡œì§] í•˜ë“œë””ìŠ¤í¬ë¥¼ ìŠ¤ìº”í•˜ì—¬ Yahooì™€ Kaggleì˜ ì¶©ëŒì„ ìë™ í•´ê²°
    """
    inventory = {} # { 'TICKER': {Info} }
    
    # 1. Yahoo í´ë” ìŠ¤ìº” (ìš°ì„ ìˆœìœ„ 1ìœ„ - ì •ë³¸)
    # Yahooì— ìˆëŠ” ê±´ ë¬´ì¡°ê±´ ê·¸ ì´ë¦„ ê·¸ëŒ€ë¡œ ê°€ì ¸ê° (ì˜ˆ: GM -> GM)
    if YAHOO_DIR.exists():
        for p in tqdm(list(YAHOO_DIR.glob("ticker=*")), desc="Scanning Yahoo (High Priority)"):
            if not p.is_dir(): continue
            ticker = p.name.split("=")[-1]
            ticker = normalize_ticker(ticker)
            
            file_path = p / "price.parquet"
            if file_path.exists():
                inventory[ticker] = {
                    'source': 'yahoo',
                    'file_path': str(file_path.relative_to(BASE_DIR)),
                    'is_active': True
                }

    # 2. Kaggle í´ë” ìŠ¤ìº” (ìš°ì„ ìˆœìœ„ 2ìœ„ - ì¶©ëŒ ì‹œ ì´ë¦„ ë³€ê²½)
    if KAGGLE_DIR.exists():
        for p in tqdm(list(KAGGLE_DIR.glob("ticker=*")), desc="Scanning Kaggle (Legacy Check)"):
            if not p.is_dir(): continue
            original_ticker = p.name.split("=")[-1]
            original_ticker = normalize_ticker(original_ticker)
            
            file_path = p / "price.parquet"
            if not file_path.exists(): continue

            # [ìë™ ì¶©ëŒ í•´ê²°]
            if original_ticker in inventory:
                # ì´ë¯¸ Yahooì—ì„œ ë“±ë¡ëœ í‹°ì»¤ë¼ë©´? -> "_OLD"ë¥¼ ë¶™ì—¬ì„œ ë³„ë„ ë“±ë¡
                # ì˜ˆ: Yahoo(GM)ì´ ìˆìœ¼ë¯€ë¡œ, Kaggle(GM) -> GM_OLDë¡œ ì¥ë¶€ ë“±ë¡
                new_ticker_name = f"{original_ticker}_OLD"
                
                # ë¡œê·¸ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬ í•˜ì„¸ìš”
                # print(f"  âš¡ï¸ ì¶©ëŒ ê°ì§€: {original_ticker} -> {new_ticker_name} (ìë™ ë³€ê²½)")
                
                inventory[new_ticker_name] = {
                    'source': 'kaggle_legacy',
                    'file_path': str(file_path.relative_to(BASE_DIR)),
                    'is_active': True # ë°ì´í„° ì‚´ë¦¼
                }
            else:
                # Yahooì—ëŠ” ì—†ëŠ” ê²½ìš° (ìƒíì£¼ ë“±) -> ì›ë˜ ì´ë¦„ ê·¸ëŒ€ë¡œ ë“±ë¡
                inventory[original_ticker] = {
                    'source': 'kaggle',
                    'file_path': str(file_path.relative_to(BASE_DIR)),
                    'is_active': True
                }
                
    return inventory

def main():
    print(">>> [Phase 1] Universe ì •ì˜ ë° ìë™ ì¶©ëŒ í•´ê²° (Auto-Resolve)")
    
    # 1. íŒŒì¼ ì‹œìŠ¤í…œ ìŠ¤ìº” (ìë™ ë§¤í•‘ ìˆ˜í–‰)
    print("  ğŸ•µï¸ ë¡œì»¬ íŒŒì¼ ì „ìˆ˜ ì¡°ì‚¬ ì¤‘...")
    local_data = scan_and_resolve_conflicts()
    print(f"  âœ… ë¡œì»¬ íŒŒì¼ ìŠ¤ìº” ì™„ë£Œ: {len(local_data)} ê°œ ì¢…ëª© ì‹ë³„ë¨")

    # 2. ê¸°ì¡´ ì¥ë¶€ ë©”íƒ€ë°ì´í„° ë°±ì—… (count, date ë“± ìœ ì§€ìš©)
    old_meta = {}
    if MASTER_PATH.exists():
        shutil.copy2(MASTER_PATH, BACKUP_PATH)
        df_old = pd.read_csv(MASTER_PATH)
        for _, row in df_old.iterrows():
            old_meta[row['ticker']] = row.to_dict()

    # 3. ìµœì¢… ë¦¬ìŠ¤íŠ¸ ë³‘í•©
    final_rows = []
    
    # [A] ë¡œì»¬ íŒŒì¼ ë“±ë¡
    for ticker, info in local_data.items():
        row = {
            'ticker': ticker,
            'source': info['source'],
            'is_active': info['is_active'],
            'file_path': info['file_path'],
            'count': 0, 
            'start_date': None, 
            'end_date': None,
            'last_updated': datetime.now().strftime("%Y-%m-%d")
        }
        
        # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë³µêµ¬ (íŒŒì¼ ê²½ë¡œê°€ ê°™ì„ ë•Œë§Œ)
        if ticker in old_meta:
            prev = old_meta[ticker]
            if str(prev.get('file_path')) == str(info['file_path']):
                row['count'] = prev.get('count', 0)
                row['start_date'] = prev.get('start_date')
                row['end_date'] = prev.get('end_date')
        
        final_rows.append(row)

    # [B] ì›¹ ì‹ ê·œ ì¢…ëª© ì¶”ê°€ (ë¡œì»¬ì— ì—†ëŠ” ê²ƒë§Œ)
    web_tickers = get_new_tickers_from_web()
    existing_keys = set(local_data.keys())
    
    new_candidates = []
    for t in web_tickers:
        # GMì´ ìˆë“  GM_OLDê°€ ìˆë“  í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì‹ ê·œ ì•„ë‹˜
        if t not in existing_keys and f"{t}_OLD" not in existing_keys:
             new_candidates.append(t)
    
    print(f"  ğŸ” ì›¹ ì‹ ê·œ ì¢…ëª© ì¶”ê°€: {len(new_candidates)} ê°œ")
    
    for t in new_candidates:
        if "$" in t: continue 
        row = {
            'ticker': t,
            'source': 'new_ipo',
            'is_active': True,
            'file_path': f"data/bronze/yahoo_price_data/ticker={t}/price.parquet",
            'count': 0,
            'start_date': None,
            'end_date': None,
            'last_updated': datetime.now().strftime("%Y-%m-%d")
        }
        final_rows.append(row)

    # 4. ì €ì¥ ë° ë©”íƒ€ë°ì´í„° ê°±ì‹ 
    df_final = pd.DataFrame(final_rows)
    
    print("  ğŸ“ ë©”íƒ€ë°ì´í„°(í–‰ ê°œìˆ˜ ë“±) ê°±ì‹  ì¤‘...")
    # ì†ë„ë¥¼ ìœ„í•´ countê°€ 0ì¸ ê²ƒë§Œ ì‹¤ì œ íŒŒì¼ ì—´ì–´ì„œ í™•ì¸
    updates = 0
    for idx, row in tqdm(df_final.iterrows(), total=len(df_final)):
        if row['source'] != 'new_ipo' and (pd.isna(row['count']) or row['count'] == 0):
            full_path = BASE_DIR / str(row['file_path'])
            if full_path.exists():
                try:
                    # í—¤ë”ë§Œ ì½ì–´ì„œ ë¹ ë¥´ê²Œ ì²˜ë¦¬
                    meta = pd.read_parquet(full_path, columns=['Close'])
                    df_final.at[idx, 'count'] = len(meta)
                    df_final.at[idx, 'start_date'] = meta.index[0].strftime("%Y-%m-%d")
                    df_final.at[idx, 'end_date'] = meta.index[-1].strftime("%Y-%m-%d")
                    updates += 1
                except:
                    pass

    df_final.to_csv(MASTER_PATH, index=False)
    
    print("\n" + "="*40)
    print("  âœ… ì¥ë¶€ ìƒì„± ì™„ë£Œ")
    print(f"  - ì´ ì¢…ëª©: {len(df_final)}")
    print(f"  - Yahoo(ì‹ ê·œ): {len(df_final[df_final['source']=='yahoo'])}")
    print(f"  - Kaggle(êµ¬í˜•/OLD): {len(df_final[df_final['source']=='kaggle_legacy'])}")
    print("="*40)

if __name__ == "__main__":
    main()