import pandas as pd
import shutil
import numpy as np
import gc
from pathlib import Path
from tqdm import tqdm
from collections import defaultdict
import warnings

# ê²½ê³  ë¬´ì‹œ
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=RuntimeWarning)

# ==========================================
# [Phase 4] Gold Layer: Ratio-Adjusted Stitching
# ==========================================
BASE_DIR = Path(__file__).resolve().parent.parent
SILVER_DIR = BASE_DIR / "data" / "silver" / "daily_prices"
GOLD_DIR = BASE_DIR / "data" / "gold" / "daily_prices"

def get_metadata(file_path):
    try:
        df = pd.read_parquet(file_path, columns=['Close'])
        if df.empty: return None
        
        start_date = df.index[0]
        end_date = df.index[-1]
        start_key = start_date.strftime("%Y-%m")
        last_price = float(df['Close'].iloc[-1])
        
        return {
            'ticker': file_path.stem,
            'path': file_path,
            'start_key': start_key,
            'start_date': start_date,
            'end_date': end_date,
            'last_price': last_price,
            'count': len(df)
        }
    except:
        return None

def calculate_correlation_optimized(meta_a, meta_b, window=120):
    """
    ìƒê´€ê³„ìˆ˜ ê³„ì‚° (ê°€ê²© í•„í„° + ìœˆë„ìš° ìŠ¬ë¼ì´ì‹±)
    * ì£¼ì˜: ìƒê´€ê³„ìˆ˜ëŠ” ìŠ¤ì¼€ì¼(x10, x0.1)ì— ì˜í–¥ì„ ë°›ì§€ ì•Šìœ¼ë¯€ë¡œ
      ì•¡ë©´ë¶„í•  ì „/í›„ ë°ì´í„°ë¼ë„ ìƒê´€ê³„ìˆ˜ëŠ” ë†’ê²Œ ë‚˜ì˜µë‹ˆë‹¤.
      ë”°ë¼ì„œ 'ë¹„ìœ¨ ë³´ì •'ì€ stitch ë‹¨ê³„ì—ì„œ ë³„ë„ë¡œ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    # 1. Price Filter (ë„ˆë¬´ í„°ë¬´ë‹ˆì—†ëŠ” ê°€ê²© ì°¨ì´ëŠ” í•„í„°ë§í•˜ë˜, ì•¡ë©´ë¶„í•  ê³ ë ¤í•˜ì—¬ ë²”ìœ„ ì™„í™”)
    # ì•¡ë©´ë¶„í• ì€ ë³´í†µ 1/10, 1/50 ë“±ì´ë¯€ë¡œ ë¹„ìœ¨ë¡œ ì²´í¬í•´ì•¼ í•¨.
    # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” 'ìƒê´€ê³„ìˆ˜'ë¥¼ ë¯¿ê³  Price FilterëŠ” ìµœì†Œí•œì˜ ë°©ì–´(0ì› ë“±)ë§Œ ìˆ˜í–‰
    p1, p2 = meta_a['last_price'], meta_b['last_price']
    if p1 == 0 or p2 == 0: return 0.0
    
    # 2. Correlation
    try:
        df_a = pd.read_parquet(meta_a['path'], columns=['Close'])
        df_b = pd.read_parquet(meta_b['path'], columns=['Close'])
        
        common = df_a.index.intersection(df_b.index)
        if len(common) < 30: return 0.0
        
        if len(common) > window:
            common = common[-window:]
            
        sa = df_a.loc[common, 'Close'].astype('float32')
        sb = df_b.loc[common, 'Close'].astype('float32')
        
        if sa.std() < 1e-6 or sb.std() < 1e-6: return 0.0
        
        return sa.corr(sb)
    except:
        return 0.0

def stitch_and_save(main_meta, sub_metas, output_dir):
    """
    [í•µì‹¬ ìˆ˜ì •] Ratio-Based Adjusting Stitching
    Main(ìµœì‹ /Yahoo) ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, Sub(ê³¼ê±°/Kaggle) ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ì„ ë³´ì •í•˜ì—¬ ë³‘í•©.
    """
    try:
        # 1. Main ë¡œë“œ (ê¸°ì¤€ ë°ì´í„° - Yahoo/ìµœì‹ )
        main_df = pd.read_parquet(main_meta['path'])
        
        # 2. Sub ìˆœíšŒí•˜ë©° ë³´ì • í›„ ë³‘í•©
        for sub in sub_metas:
            sub_df = pd.read_parquet(sub['path'])
            
            # --- [Adjusting Logic Start] ---
            # ê²¹ì¹˜ëŠ” êµ¬ê°„ ì°¾ê¸°
            common_idx = main_df.index.intersection(sub_df.index)
            
            if not common_idx.empty:
                # ê²¹ì¹˜ëŠ” êµ¬ê°„ ì¤‘ 'ê°€ì¥ ìµœì‹  ë‚ ì§œ'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¹„ìœ¨ ê³„ì‚°
                # (ê³¼ê±° ë‚ ì§œë³´ë‹¤ ìµœì‹  ë‚ ì§œê°€ ë°ì´í„° ì •í•©ì„±ì´ ë†’ì„ í™•ë¥ ì´ í¼)
                pivot_date = common_idx[-1]
                
                p_main = float(main_df.loc[pivot_date, 'Close'])
                p_sub = float(sub_df.loc[pivot_date, 'Close'])
                
                if p_sub != 0:
                    ratio = p_main / p_sub
                    
                    # ë¹„ìœ¨ì´ 1.0ê³¼ ìœ ì˜ë¯¸í•˜ê²Œ ì°¨ì´ë‚˜ë©´ (ì˜ˆ: 1% ì´ìƒ) -> ë³´ì • ìˆ˜í–‰
                    # ì˜ˆ: main=12ë§Œì›, sub=120ë§Œì› -> ratio=0.1
                    if abs(1.0 - ratio) > 0.01:
                        # ìˆ«ìí˜• ì»¬ëŸ¼ ì „ì²´ì— ë¹„ìœ¨ ê³±í•˜ê¸° (Open, High, Low, Close, Volume ë“±)
                        # ì£¼ì˜: Volumeì€ ì£¼ê°€ê°€ ë‚®ì•„ì§€ë©´(ì•¡ë©´ë¶„í• ) ë³´í†µ ëŠ˜ì–´ë‚˜ë¯€ë¡œ ë°˜ëŒ€ë¡œ ë‚˜ëˆ ì•¼ í•  ìˆ˜ë„ ìˆìœ¼ë‚˜,
                        # Yahooì˜ ìˆ˜ì •ì£¼ê°€(Adj Close) ë¡œì§ì„ ë”°ë¼ê°€ê¸° ìœ„í•´ ê°€ê²©ì€ ê³±í•˜ê³ , ë³¼ë¥¨ì€ ë‚˜ëˆ„ëŠ”ê²Œ ì •ì„.
                        # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ê°€ê²©ë§Œ ë³´ì •í•˜ê±°ë‚˜, Volumeë„ ê°™ì€ ë¹„ìœ¨ë¡œ ì¡°ì •(Splitì˜ ì—­)
                        
                        # [Price Correction]
                        price_cols = [c for c in ['Open', 'High', 'Low', 'Close', 'Adj Close'] if c in sub_df.columns]
                        sub_df[price_cols] = sub_df[price_cols] * ratio
                        
                        # [Volume Correction]
                        # ì•¡ë©´ë¶„í• (ì£¼ê°€ 1/10) -> ê±°ë˜ëŸ‰(10ë°°) ì´ì–´ì•¼ í•¨.
                        # ì£¼ê°€ ratioê°€ 0.1ì´ë©´, Volumeì€ 1/0.1 = 10ë°°ê°€ ë˜ì–´ì•¼ í•¨.
                        if 'Volume' in sub_df.columns:
                            sub_df['Volume'] = sub_df['Volume'] / ratio
                            
                        # print(f"    ğŸ”§ Adjusting {sub['ticker']} by ratio {ratio:.4f} (Pivot: {pivot_date.date()})")
            
            # --- [Adjusting Logic End] ---

            # 3. ë³‘í•© (Main ìš°ì„ , ë¹ˆ ê³³ì„ ë³´ì •ëœ Subë¡œ ì±„ì›€)
            main_df = main_df.combine_first(sub_df)
            
        # 4. ë°ì´í„° ì •ë¦¬
        main_df = main_df[~main_df.index.duplicated(keep='last')]
        main_df.sort_index(inplace=True)

        # 5. Gatekeeper (ìŒìˆ˜ ë° ê¸‰ë“±ë½ í™•ì¸)
        cols = [c for c in ['Open','High','Low','Close'] if c in main_df.columns]
        if (main_df[cols] < 0).any().any(): return False

        pct = main_df['Close'].pct_change().dropna()
        # ë³´ì •ì„ í–ˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ë¯¸ì¹œ ë³€ë™ì„±ì´ ìˆë‹¤ë©´ Reject
        if ((pct > 3.0) | (pct < -0.9)).any():
            return False

        # 6. ì €ì¥
        save_path = output_dir / f"{main_meta['ticker']}.parquet"
        main_df.to_parquet(save_path)
        return True
    except Exception as e:
        # print(f"Error merging: {e}")
        return False

def main():
    print(">>> [Phase 4] Gold Layer ìƒì„± (Ratio Adjusted)")
    
    if GOLD_DIR.exists(): shutil.rmtree(GOLD_DIR)
    GOLD_DIR.mkdir(parents=True, exist_ok=True)
    
    silver_files = list(SILVER_DIR.glob("*.parquet"))
    print(f"  ğŸ“– Silver íŒŒì¼ ìŠ¤ìº”: {len(silver_files)} ê°œ")

    buckets = defaultdict(list)
    for f in tqdm(silver_files, desc="Bucketing"):
        meta = get_metadata(f)
        if meta: buckets[meta['start_key']].append(meta)

    success_count = 0
    dedup_count = 0
    
    print("  ğŸ” ë¶„ì„ ë° ë³‘í•© (Price Adjusting ì ìš©)...")
    
    sorted_keys = sorted(buckets.keys())
    pbar = tqdm(sorted_keys)
    
    for key in pbar:
        candidates = buckets[key]
        n = len(candidates)
        pbar.set_description(f"Bucket {key} ({n})")
        
        if n == 1:
            meta = candidates[0]
            shutil.copy2(meta['path'], GOLD_DIR / f"{meta['ticker']}.parquet")
            success_count += 1
            continue
            
        candidates.sort(key=lambda x: (x['end_date'], x['count']), reverse=True)
        processed = set()
        
        for i in range(n):
            main = candidates[i]
            if main['ticker'] in processed: continue
            
            duplicates = []
            for j in range(i + 1, n):
                sub = candidates[j]
                if sub['ticker'] in processed: continue
                
                corr = calculate_correlation_optimized(main, sub)
                if corr > 0.99:
                    duplicates.append(sub)
                    processed.add(sub['ticker'])
                    dedup_count += 1
            
            if duplicates:
                saved = stitch_and_save(main, duplicates, GOLD_DIR)
                if saved: success_count += 1
            else:
                shutil.copy2(main['path'], GOLD_DIR / f"{main['ticker']}.parquet")
                success_count += 1
            
            processed.add(main['ticker'])
            
        if n > 1000: gc.collect()

    print("\n" + "="*40)
    print(f"  âœ… Gold Layer ì™„ë£Œ")
    print(f"  - ìµœì¢… ì €ì¥: {success_count}")
    print(f"  - í†µí•© ë° ë³´ì •: {dedup_count}")
    print("="*40)

if __name__ == "__main__":
    main()