import pandas as pd
import yfinance as yf
import time
import random
from pathlib import Path
from datetime import datetime
from tqdm import tqdm

# ==========================================
# [Phase 2] Smart Download (Safe Mode & Filtered)
# ==========================================
BASE_DIR = Path(__file__).resolve().parent.parent
MASTER_PATH = BASE_DIR / "data" / "bronze" / "master_ticker_list.csv"
YAHOO_DATA_DIR = BASE_DIR / "data" / "bronze" / "yahoo_price_data"

# [ì•ˆì „ ì„¤ì •] ì†ë„ë¥¼ ì¤„ì—¬ì„œ ì°¨ë‹¨ì„ ë°©ì§€í•¨
BATCH_SIZE = 20
USE_THREADS = False  # Trueë©´ ë¹ ë¥´ì§€ë§Œ ì°¨ë‹¨ë¨ -> Falseë¡œ ì•ˆì „í•˜ê²Œ

def normalize_ticker_for_download(ticker):
    return str(ticker).replace(".", "-").upper()

def is_junk_ticker(ticker):
    """
    ë¶„ì„ ê°€ì¹˜ê°€ ì—†ëŠ” ì›ŒëŸ°íŠ¸(W), ê¶Œë¦¬(R), ìœ ë‹›(U), ìš°ì„ ì£¼(P) ë“±ì„ í•„í„°ë§
    ì˜ˆ: JOBY-WT, AGFSW, HYAC-U
    """
    t = str(ticker).upper()
    
    # ëª…ë°±í•œ ì›ŒëŸ°íŠ¸ í‘œê¸°
    if "-WT" in t or "WARRANT" in t: return True
    
    # 5ê¸€ì ì´ìƒì¸ë° ëìë¦¬ê°€ íŒŒìƒìƒí’ˆ ì½”ë“œì¸ ê²½ìš°
    # (NASDAQ ë°ì´í„°ì—ì„œ í”í•¨)
    if len(t) >= 5:
        suffix = t[-1]
        if suffix in ['W', 'R', 'P', 'U', 'Z']: # W:Warrant, R:Right, P:Preferred, U:Unit
            return True
            
    return False

def main():
    print(">>> [Phase 2] ì•ˆì „ëª¨ë“œ ë‹¤ìš´ë¡œë“œ (Junk Filter + Anti-Ban)")
    
    if not MASTER_PATH.exists():
        print("âŒ ì¥ë¶€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1. ì¥ë¶€ ë¡œë“œ
    df = pd.read_csv(MASTER_PATH)
    
    # 2. íƒ€ê²Ÿ ì„ ì • (Count=0)
    df['count'] = pd.to_numeric(df['count'], errors='coerce').fillna(0)
    raw_targets = df[df['count'] == 0]['ticker'].tolist()
    
    print(f"  ğŸ“– ì›ë³¸ ëŒ€ìƒ: {len(raw_targets)} ê°œ")
    
    # [í•„í„°ë§] ì“°ë ˆê¸° í‹°ì»¤ ì œê±°
    clean_targets = []
    skipped_junk = 0
    
    for t in raw_targets:
        if is_junk_ticker(t):
            skipped_junk += 1
            # ì¥ë¶€ì—ëŠ” 'N/A' ë“±ìœ¼ë¡œ í‘œì‹œí•´ë‘ë©´ ì¢‹ì§€ë§Œ, ì¼ë‹¨ì€ ê±´ë„ˆëœ€
        else:
            clean_targets.append(t)
            
    print(f"  ğŸ—‘ï¸ íŒŒìƒìƒí’ˆ(W/R/U) ì œì™¸: {skipped_junk} ê°œ")
    print(f"  ğŸ¯ ìµœì¢… ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ: {len(clean_targets)} ê°œ")
    
    if not clean_targets:
        print("âœ… ë‹¤ìš´ë¡œë“œí•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3. ë°°ì¹˜ ë‹¤ìš´ë¡œë“œ
    chunks = [clean_targets[i:i + BATCH_SIZE] for i in range(0, len(clean_targets), BATCH_SIZE)]
    
    success_cnt = 0
    fail_cnt = 0
    today_str = datetime.now().strftime("%Y-%m-%d")
    
    print(f"  ğŸš€ ë‹¤ìš´ë¡œë“œ ì‹œì‘ (ë°°ì¹˜: {BATCH_SIZE}, ìŠ¤ë ˆë“œ: {USE_THREADS})")
    
    for chunk in tqdm(chunks, desc="Downloading"):
        try:
            yahoo_tickers = [normalize_ticker_for_download(t) for t in chunk]
            
            # [ìš”ì²­] ì—ëŸ¬ë‚˜ë©´ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
            try:
                data = yf.download(
                    yahoo_tickers, 
                    period="max", 
                    auto_adjust=True, 
                    group_by='ticker', 
                    progress=False, 
                    threads=USE_THREADS  # ì•ˆì „ëª¨ë“œ
                )
            except Exception as e:
                print(f"  âš ï¸ ë„¤íŠ¸ì›Œí¬/API ì—ëŸ¬, 10ì´ˆ ëŒ€ê¸°... ({e})")
                time.sleep(10)
                continue
            
            if data is None or data.empty:
                fail_cnt += len(chunk)
                continue

            # ê²°ê³¼ ì²˜ë¦¬
            for t_raw, t_yahoo in zip(chunk, yahoo_tickers):
                try:
                    if len(yahoo_tickers) == 1:
                        sub_df = data
                    else:
                        if t_yahoo not in data.columns.levels[0]:
                            fail_cnt += 1
                            continue
                        sub_df = data[t_yahoo].copy()
                    
                    # ìœ íš¨ì„± ê²€ì‚¬
                    if sub_df.isnull().all().all():
                        fail_cnt += 1
                        continue
                    
                    sub_df.dropna(how='all', inplace=True)
                    if sub_df.empty:
                        fail_cnt += 1
                        continue

                    # ì¸ë±ìŠ¤ ì •ë¦¬
                    if not isinstance(sub_df.index, pd.DatetimeIndex):
                        sub_df.reset_index(inplace=True)
                        if 'Date' in sub_df.columns:
                            sub_df['Date'] = pd.to_datetime(sub_df['Date'])
                            sub_df.set_index('Date', inplace=True)
                    
                    if sub_df.index.tz is not None:
                        sub_df.index = sub_df.index.tz_localize(None)
                    
                    sub_df.sort_index(inplace=True)

                    # ì €ì¥
                    save_dir = YAHOO_DATA_DIR / f"ticker={t_raw}"
                    save_dir.mkdir(parents=True, exist_ok=True)
                    save_path = save_dir / "price.parquet"
                    sub_df.to_parquet(save_path)
                    
                    # ì¥ë¶€ ì—…ë°ì´íŠ¸
                    idx = df[df['ticker'] == t_raw].index
                    if not idx.empty:
                        df.loc[idx, 'start_date'] = sub_df.index[0].strftime("%Y-%m-%d")
                        df.loc[idx, 'end_date'] = sub_df.index[-1].strftime("%Y-%m-%d")
                        df.loc[idx, 'count'] = len(sub_df)
                        df.loc[idx, 'file_path'] = str(save_path.relative_to(BASE_DIR))
                        df.loc[idx, 'last_updated'] = today_str
                        df.loc[idx, 'source'] = 'yahoo_new'
                        df.loc[idx, 'is_active'] = True
                    
                    success_cnt += 1
                    
                except Exception:
                    fail_cnt += 1
            
            # Rate Limit ë°©ì§€ë¥¼ ìœ„í•œ ì¶©ë¶„í•œ íœ´ì‹
            time.sleep(random.uniform(2.0, 4.0))
            
        except Exception as e:
            print(f"Batch Error: {e}")
            fail_cnt += len(chunk)
            df.to_csv(MASTER_PATH, index=False) # ì¤‘ê°„ ì €ì¥

    # 4. ìµœì¢… ì €ì¥
    df.to_csv(MASTER_PATH, index=False)
    
    print("\n" + "="*40)
    print("  âœ… ì™„ë£Œ")
    print(f"  - ì„±ê³µ: {success_cnt}")
    print(f"  - ì‹¤íŒ¨/ì—†ìŒ: {fail_cnt}")
    print(f"  - ì œì™¸ëœ Junk: {skipped_junk}")
    print(f"  ğŸ“‚ {MASTER_PATH}")

if __name__ == "__main__":
    main()