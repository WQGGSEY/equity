import os
import json
import shutil
import pandas as pd
from pathlib import Path
from tqdm import tqdm

# ==========================================
# [ì„¤ì •]
# ==========================================
BASE_DIR = Path(__file__).resolve().parent.parent

# ì…ë ¥ ê²½ë¡œ
OLD_KAGGLE_DIR = BASE_DIR / "data" / "bronze" / "daily_prices"
NEW_YAHOO_DIR = BASE_DIR / "data" / "temp_reference"
PLAN_PATH = BASE_DIR / "data" / "bronze" / "fix_plan.json"
OLD_MASTER_PATH = BASE_DIR / "data" / "bronze" / "master_ticker_list.csv"

# ì¶œë ¥ ê²½ë¡œ (ì‹ ëŒ€ë¥™)
TARGET_DIR = BASE_DIR / "data" / "bronze" / "daily_prices_combined"
NEW_MASTER_PATH = BASE_DIR / "data" / "bronze" / "master_ticker_list_updated.csv"

def main():
    print(">>> [Phase 3] Constructing New Dataset (Copy Mode)")
    
    # 1. ì¤€ë¹„
    if not PLAN_PATH.exists():
        raise FileNotFoundError("ì‘ì „ ì§€ë„(fix_plan.json)ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with open(PLAN_PATH, 'r') as f:
        plan = json.load(f)
        
    # ê¸°ì¡´ ë§ˆìŠ¤í„° ë¡œë“œ (ë©”íƒ€ë°ì´í„° ì°¸ì¡°ìš©)
    if not OLD_MASTER_PATH.exists():
         raise FileNotFoundError("ê¸°ì¡´ ë§ˆìŠ¤í„° ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
         
    old_master = pd.read_csv(OLD_MASTER_PATH)
    
    # [FIX] ì¤‘ë³µ í‹°ì»¤ ì œê±° ë¡œì§ ì¶”ê°€
    # í‹°ì»¤ê°€ ì¤‘ë³µë˜ë©´ ì²« ë²ˆì§¸ í–‰ë§Œ ë‚¨ê¸°ê³  ì œê±°í•©ë‹ˆë‹¤.
    # (ë©”íƒ€ë°ì´í„° ì¡°íšŒìš©ì´ë¯€ë¡œ ì¤‘ë³µëœ ê²ƒ ì¤‘ í•˜ë‚˜ë§Œ ìˆì–´ë„ ë¬´ë°©í•©ë‹ˆë‹¤)
    duplicate_count = old_master.duplicated(subset=['ticker']).sum()
    if duplicate_count > 0:
        print(f"âš ï¸ ê²½ê³ : ë§ˆìŠ¤í„° ë¦¬ìŠ¤íŠ¸ì—ì„œ {duplicate_count}ê°œì˜ ì¤‘ë³µ í‹°ì»¤ë¥¼ ë°œê²¬í•˜ì—¬ ì œê±°í•©ë‹ˆë‹¤.")
        old_master = old_master.drop_duplicates(subset=['ticker'], keep='first')
    
    # tickerë¥¼ ì¸ë±ìŠ¤ë¡œ ë§Œë“¤ì–´ ë¹ ë¥¸ ì¡°íšŒ (ì´ì œ ì—ëŸ¬ ì•ˆ ë‚¨)
    master_lookup = old_master.set_index('ticker').to_dict('index')
    
    # íƒ€ê²Ÿ í´ë” ìƒì„±
    TARGET_DIR.mkdir(parents=True, exist_ok=True)
    print(f"  ğŸ“‚ íƒ€ê²Ÿ í´ë”: {TARGET_DIR}")
    
    new_master_rows = []
    
    # 2. ì‹¤í–‰ ë£¨í”„
    print(">>> íŒŒì¼ ì´ë™ ë° í†µí•© ì‹œì‘...")
    
    stats = {"copied_yahoo": 0, "copied_kaggle": 0, "errors": 0}
    
    for item in tqdm(plan, desc="Executing Plan"):
        action = item['action']
        original_ticker = item['ticker']
        
        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        meta = master_lookup.get(original_ticker, {})
        
        # ìƒˆ í•­ëª©ì„ ìœ„í•œ ê¸°ë³¸ ë”•ì…”ë„ˆë¦¬
        new_entry = {
            "ticker": original_ticker,
            "source": "unknown",
            "is_active": False,
            "original_ticker": original_ticker, 
            "start_date": meta.get('start_date'),
            "end_date": meta.get('end_date'),
            "count": meta.get('count'),
            "file_path": ""
        }

        try:
            # ---------------------------------------------------
            # CASE A: Yahoo ë°ì´í„° ì±„íƒ (MERGE, RENAME)
            # ---------------------------------------------------
            if action in ['MERGE', 'RENAME']:
                target_ticker = item['new_name'] if action == 'RENAME' else original_ticker
                
                # ì†ŒìŠ¤: Yahoo Temp
                src_path = NEW_YAHOO_DIR / f"ticker={target_ticker}" / "price.parquet"
                
                if not src_path.exists():
                    if 'target_path' in item and item['target_path']:
                        src_path = Path(item['target_path'])
                
                if src_path.exists():
                    # íƒ€ê²Ÿ ê²½ë¡œ ì„¤ì •
                    dest_folder = TARGET_DIR / f"ticker={target_ticker}"
                    dest_folder.mkdir(exist_ok=True)
                    dest_path = dest_folder / "price.parquet"
                    
                    # ë³µì‚¬
                    shutil.copy2(src_path, dest_path)
                    
                    # ë§ˆìŠ¤í„° ì •ë³´ ì—…ë°ì´íŠ¸
                    new_entry['ticker'] = target_ticker
                    new_entry['source'] = 'yahoo'
                    new_entry['is_active'] = True
                    new_entry['file_path'] = str(dest_path.relative_to(BASE_DIR))
                    new_entry['last_updated'] = pd.Timestamp.now().strftime('%Y-%m-%d')
                    
                    stats['copied_yahoo'] += 1
                else:
                    # ì•¼í›„ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ì¹´ìš´íŠ¸
                    # (í•˜ì§€ë§Œ plan ìƒì„± ì‹œì ê³¼ ì‹¤í–‰ ì‹œì  ì°¨ì´ë¡œ ì—†ì„ ìˆ˜ë„ ìˆìŒ)
                    print(f"âš ï¸ [Skip] Yahoo Source Missing: {target_ticker}")
                    stats['errors'] += 1
                    continue

            # ---------------------------------------------------
            # CASE B: Kaggle ë°ì´í„° ë³´ì¡´ (FORK, MISSING)
            # ---------------------------------------------------
            elif action in ['FORK', 'MISSING']:
                target_ticker = item['new_name'] if action == 'FORK' else original_ticker
                
                # ì†ŒìŠ¤: Old Kaggle
                src_path_str = meta.get('file_path', '')
                if not src_path_str:
                    src_path = OLD_KAGGLE_DIR / f"ticker={original_ticker}" / "price.parquet"
                else:
                    src_path = BASE_DIR / src_path_str
                
                if src_path.exists():
                    dest_folder = TARGET_DIR / f"ticker={target_ticker}"
                    dest_folder.mkdir(exist_ok=True)
                    dest_path = dest_folder / "price.parquet"
                    
                    shutil.copy2(src_path, dest_path)
                    
                    new_entry['ticker'] = target_ticker
                    new_entry['source'] = 'kaggle'
                    new_entry['is_active'] = False
                    new_entry['file_path'] = str(dest_path.relative_to(BASE_DIR))
                    
                    stats['copied_kaggle'] += 1
                else:
                    print(f"âš ï¸ [Skip] Kaggle Source Missing: {original_ticker}")
                    stats['errors'] += 1
                    continue
            
            # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            new_master_rows.append(new_entry)

        except Exception as e:
            print(f"âŒ Error processing {original_ticker}: {e}")
            stats['errors'] += 1

    # 3. ìƒˆë¡œìš´ ë§ˆìŠ¤í„° íŒŒì¼ ì €ì¥
    new_master_df = pd.DataFrame(new_master_rows)
    # ìµœì¢…ì ìœ¼ë¡œ ì—¬ê¸°ì„œë„ ì¤‘ë³µ ì œê±° (í˜¹ì‹œ ëª¨ë¥´ë‹ˆ)
    new_master_df = new_master_df.drop_duplicates(subset=['ticker'])
    
    new_master_df.to_csv(NEW_MASTER_PATH, index=False)
    
    print("\n" + "="*40)
    print(">>> [Phase 3 ì™„ë£Œ] ìƒˆë¡œìš´ ë°ì´í„°ì…‹ êµ¬ì¶• ì„±ê³µ")
    print("="*40)
    print(f"  âœ… Yahoo ë°ì´í„° ì´ì‹: {stats['copied_yahoo']}ê±´")
    print(f"  âœ… Kaggle ë°ì´í„° ë³´ì¡´: {stats['copied_kaggle']}ê±´")
    print(f"  âŒ ì—ëŸ¬/ìŠ¤í‚µ: {stats['errors']}ê±´")
    print(f"  ğŸ“‚ ë°ì´í„° ìœ„ì¹˜: {TARGET_DIR}")
    print(f"  ğŸ“ ìƒˆ ë§ˆìŠ¤í„° íŒŒì¼: {NEW_MASTER_PATH}")
    print("\n[ì•ˆë‚´] ê²€ì¦ í›„ ê¸°ì¡´ í´ë”(daily_prices)ë¥¼ ì‚­ì œí•˜ê±°ë‚˜ ì•„ì¹´ì´ë¹™í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()