import pandas as pd
import requests
import shutil
from datetime import datetime
from src.config import *

# ì†ŒìŠ¤ ì •ì˜
SEC_HEADERS = {'User-Agent': 'Individual_Researcher my_email@example.com'}
SEC_URL = "https://www.sec.gov/files/company_tickers.json"
NASDAQ_URL = "ftp://ftp.nasdaqtrader.com/SymbolDirectory/nasdaqtraded.txt"

def get_new_tickers_from_web():
    """ì›¹ì—ì„œ ìµœì‹  ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘"""
    found_tickers = set()
    print("  ğŸ“¡ ì‹ ê·œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ í™•ì¸ ì¤‘ (SEC/NASDAQ)...")
    
    try:
        resp = requests.get(SEC_URL, headers=SEC_HEADERS, timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            df = pd.DataFrame.from_dict(data, orient='index')
            ts = df['ticker'].astype(str).str.strip().str.upper().str.replace(".", "-")
            found_tickers.update(ts.tolist())
    except: pass

    try:
        df = pd.read_csv(NASDAQ_URL, sep="|")
        ts = df[df['Test Issue'] == 'N']['Symbol'].dropna().astype(str).str.strip().str.upper().str.replace(".", "-")
        found_tickers.update(ts.tolist())
    except: pass
        
    return found_tickers

def run_audit():
    print(">>> [Phase 1] Bronze Auditor (Backup & Ledger Check)")
    
    # [Safety] ì¥ë¶€ ë°±ì—…
    if MASTER_PATH.exists():
        BACKUP_ROOT.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        backup_path = BACKUP_ROOT / f"master_ticker_list_{timestamp}.csv"
        try:
            shutil.copy2(MASTER_PATH, backup_path)
            print(f"  ğŸ›¡ï¸ ì¥ë¶€ ë°±ì—… ì™„ë£Œ: {backup_path.name}")
        except Exception as e:
            print(f"  âš ï¸ ë°±ì—… ì‹¤íŒ¨: {e}")

    # ì¥ë¶€ ë¡œë“œ ë° ì´ˆê¸°í™”
    if not MASTER_PATH.exists():
        print("âŒ ì¥ë¶€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (scripts/01_define_universe.py ì‹¤í–‰ ê¶Œì¥)")
        return

    df = pd.read_csv(MASTER_PATH, dtype={'ticker': str}, keep_default_na=False)
    
    # Audit: íŒŒì¼ ì‹¤ì¡´ ì—¬ë¶€ í™•ì¸
    print(f"  ğŸ•µï¸ ë“±ë¡ëœ {len(df)}ê°œ ì¢…ëª© ìƒíƒœ ì ê²€...")
    updates = 0
    today_str = datetime.now().strftime(DATE_FORMAT)
    
    for idx, row in df.iterrows():
        if pd.isna(row['file_path']): continue
        full_path = BASE_DIR / str(row['file_path'])
        
        if full_path.exists():
            # ë©”íƒ€ë°ì´í„° ê°±ì‹  (ì˜¤ëŠ˜ ë¯¸í™•ì¸ ê±´ë§Œ)
            if str(row['last_updated']) != today_str or row['count'] == 0:
                try:
                    meta = pd.read_parquet(full_path, columns=['Close'])
                    df.at[idx, 'count'] = len(meta)
                    df.at[idx, 'start_date'] = meta.index[0].strftime(DATE_FORMAT)
                    df.at[idx, 'end_date'] = meta.index[-1].strftime(DATE_FORMAT)
                    df.at[idx, 'last_updated'] = today_str
                    updates += 1
                except:
                    df.at[idx, 'count'] = 0 # íŒŒì¼ ê¹¨ì§
        else:
            if row['count'] > 0:
                df.at[idx, 'count'] = 0 # ìœ ì‹¤ë¨ -> ì¬ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ

    # ì‹ ê·œ ì¢…ëª© ì¶”ê°€
    current = set(df['ticker'].unique())
    web = get_new_tickers_from_web()
    new_candidates = sorted(list(web - current))
    
    if new_candidates:
        print(f"  âœ¨ ì‹ ê·œ ìƒì¥ ë°œê²¬: {len(new_candidates)} ê°œ")
        new_rows = []
        for t in new_candidates:
            if "$" in t: continue
            new_rows.append({
                'ticker': t,
                'source': 'new_ipo',
                'is_active': True,
                'file_path': f"data/bronze/yahoo_price_data/ticker={t}/price.parquet",
                'count': 0,
                'start_date': None,
                'end_date': None,
                'last_updated': today_str
            })
        if new_rows:
            df = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)

    df.to_csv(MASTER_PATH, index=False)
    print(f"  âœ… Audit ì™„ë£Œ (ê°±ì‹ : {updates}, ì´: {len(df)})")

if __name__ == "__main__":
    run_audit()