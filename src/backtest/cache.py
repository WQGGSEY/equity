import os
import shutil
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta

CACHE_DIR = Path(__file__).resolve().parent.parent.parent / "data" / "cache"

class CacheManager:
    def __init__(self, cache_dir=CACHE_DIR):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def get_cache_path(self, name):
        return self.cache_dir / name

    def save(self, data, name):
        """
        [Final Fix] Dynamic Type Checking
        ì´ë¦„ì´ ì•„ë‹ˆë¼ 'ì‹¤ì œ ê°’ì˜ í¬ê¸°'ë¥¼ ë³´ê³  float16/float32ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        """
        path = self.get_cache_path(name)
        if path.exists():
            shutil.rmtree(path)
        path.mkdir(parents=True, exist_ok=True)
        
        print(f"ðŸ“¦ [Cache] Saving '{name}' (Dynamic Type Check)...")
        
        meta = {
            'tickers': data.get('tickers', []),
            'dates': [d.strftime('%Y-%m-%d') for d in data.get('dates', [])]
        }
        with open(path / 'meta.json', 'w') as f:
            json.dump(meta, f)

        for category in ['prices', 'features']:
            dct = data.get(category, {})
            save_dir = path / category
            save_dir.mkdir(exist_ok=True)
            
            for key, df in dct.items():
                file_path = save_dir / f"{key}.parquet"
                
                # 1. ê°€ê²© ë°ì´í„°ëŠ” ë¬´ì¡°ê±´ ì•ˆì „í•˜ê²Œ float32 (ë°±í…ŒìŠ¤íŠ¸ í•µì‹¬ì´ë¯€ë¡œ)
                if category == 'prices' or key in ['Open', 'High', 'Low', 'Close']:
                    df.astype('float32').to_parquet(file_path, engine='pyarrow', compression='zstd')
                    continue

                # 2. FeaturesëŠ” ê°’ì˜ ë²”ìœ„ë¥¼ í™•ì¸í•˜ì—¬ ë™ì  ê²°ì •
                # (1) ì ˆëŒ€ê°’ì˜ ìµœëŒ“ê°’ ê³„ì‚° (NaN/Inf ì œì™¸)
                # numeric_only=TrueëŠ” ì•ˆì „ìž¥ì¹˜
                try:
                    # infê°€ ìžˆìœ¼ë©´ maxê°€ infê°€ ë¨ -> float32ë¡œ ì²˜ë¦¬ë¨ (OK)
                    max_val = df.abs().max(numeric_only=True).max()
                except:
                    max_val = float('inf') # ê³„ì‚° ì‹¤íŒ¨ì‹œ ì•ˆì „í•˜ê²Œ float32ë¡œ

                # (2) float16 í•œê³„(ì•½ 65,500) ì²´í¬
                # ì—¬ìœ  ìžˆê²Œ 60,000 ë„˜ìœ¼ë©´ float32ë¡œ ì „í™˜
                if pd.isna(max_val) or max_val > 60000:
                    # ë²”ìœ„ ì´ˆê³¼ í˜¹ì€ inf í¬í•¨ ì‹œ
                    # print(f"   ðŸ›¡ï¸ Using float32 for '{key}' (Max: {max_val:.1f})")
                    df.astype('float32').to_parquet(file_path, engine='pyarrow', compression='zstd')
                else:
                    # ì•ˆì „ ë²”ìœ„ ë‚´ë¼ë©´ ì••ì¶•
                    df.astype('float16').to_parquet(file_path, engine='pyarrow', compression='zstd')

        total_size = sum(f.stat().st_size for f in path.rglob('*') if f.is_file()) / (1024*1024)
        print(f"   -> Save Complete. Total Size: {total_size:.2f} MB")

    def load(self, name, expiration_hours=24):
        path = self.get_cache_path(name)
        if not path.exists(): return None
        
        meta_path = path / 'meta.json'
        if not meta_path.exists(): return None
        
        mtime = datetime.fromtimestamp(os.path.getmtime(meta_path))
        if datetime.now() - mtime > timedelta(hours=expiration_hours):
            print(f"âš ï¸ [Cache] '{name}' expired. Reloading...")
            return None

        print(f"ðŸš€ [Cache] Loading '{name}'...")
        try:
            with open(meta_path, 'r') as f:
                meta = json.load(f)
            
            dates = [pd.Timestamp(d) for d in meta['dates']]
            tickers = meta['tickers']
            
            data = {'prices': {}, 'features': {}, 'dates': dates, 'tickers': tickers}
            
            for category in ['prices', 'features']:
                target_dir = path / category
                if target_dir.exists():
                    for f in target_dir.glob("*.parquet"):
                        key = f.stem
                        # ë¡œë“œí•  ë•ŒëŠ” ì—°ì‚° íŽ¸ì˜ë¥¼ ìœ„í•´ float32ë¡œ í†µì¼
                        df = pd.read_parquet(f).astype('float32')
                        data[category][key] = df
            
            return data

        except Exception as e:
            print(f"   -> Cache corrupted: {e}")
            return None