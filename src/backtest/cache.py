import os
import shutil
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta

CACHE_DIR = Path(__file__).resolve().parent.parent.parent / "data" / "cache"
class CacheManager:
    def __init__(self, cache_dir=CACHE_DIR):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def get_cache_path(self, name):
        # íŒŒì¼ì´ ì•„ë‹ˆë¼ 'ë””ë ‰í† ë¦¬'ë¥¼ ìºì‹œ ë‹¨ìœ„ë¡œ ì”ë‹ˆë‹¤.
        return self.cache_dir / name

    def save(self, data, name):
        """
        ë°ì´í„°ë¥¼ Parquet íŒŒì¼ë“¤ë¡œ ìª¼ê°œì„œ ì €ìž¥ (The Crazy Method)
        """
        path = self.get_cache_path(name)
        if path.exists():
            shutil.rmtree(path)
        path.mkdir(parents=True, exist_ok=True)
        
        print(f"ðŸ“¦ [Cache] Saving '{name}' (Parquet Sharding Mode)...")
        
        # 1. ë©”íƒ€ë°ì´í„° ì €ìž¥ (Tickers, Dates)
        meta = {
            'tickers': data.get('tickers', []),
            'dates': [d.strftime('%Y-%m-%d') for d in data.get('dates', [])]
        }
        with open(path / 'meta.json', 'w') as f:
            json.dump(meta, f)

        # 2. DataFrame ì €ìž¥ (Parquet + Zstd)
        # Pricesì™€ Featuresë¥¼ ìˆœíšŒí•˜ë©° ê°ê° ë³„ë„ íŒŒì¼ë¡œ ì €ìž¥
        for category in ['prices', 'features']:
            dct = data.get(category, {})
            save_dir = path / category
            save_dir.mkdir(exist_ok=True)
            
            for key, df in dct.items():
                # [í•µì‹¬ 1] FeatureëŠ” Float16ìœ¼ë¡œ ì••ì¶• (ìš©ëŸ‰ 50% ì ˆê°)
                # FD, Return, Correlation ë“±ì€ float16ìœ¼ë¡œ ì¶©ë¶„í•¨
                # ë‹¨, Price(ê°€ê²©)ì™€ Amount(ê±°ëž˜ëŒ€ê¸ˆ)ëŠ” ë²”ìœ„ê°€ í¬ë¯€ë¡œ float32 ìœ ì§€
                if category == 'features' or key not in ['Open', 'High', 'Low', 'Close', 'Volume', 'Amount', 'Trd_Amt', 'TrdAmount']:
                    df_to_save = df.astype('float16')
                else:
                    df_to_save = df.astype('float32')
                
                # [í•µì‹¬ 2] Parquet + Zstd ì••ì¶• (ì‹œê³„ì—´ ì••ì¶• íš¨ìœ¨ ê·¹ëŒ€í™”)
                file_path = save_dir / f"{key}.parquet"
                df_to_save.to_parquet(file_path, engine='pyarrow', compression='zstd')
                
        # ìš©ëŸ‰ í™•ì¸
        total_size = sum(f.stat().st_size for f in path.rglob('*') if f.is_file()) / (1024*1024)
        print(f"   -> Save Complete. Total Size: {total_size:.2f} MB")

    def load(self, name, expiration_hours=24):
        path = self.get_cache_path(name)
        if not path.exists(): return None
        
        # ì‹œê°„ ì²´í¬ (ë©”íƒ€íŒŒì¼ ê¸°ì¤€)
        meta_path = path / 'meta.json'
        if not meta_path.exists(): return None
        
        mtime = datetime.fromtimestamp(os.path.getmtime(meta_path))
        if datetime.now() - mtime > timedelta(hours=expiration_hours):
            print(f"âš ï¸ [Cache] '{name}' expired. Reloading...")
            return None

        print(f"ðŸš€ [Cache] Loading '{name}' (Parquet Shards)...")
        try:
            # 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ
            with open(meta_path, 'r') as f:
                meta = json.load(f)
            
            dates = [pd.Timestamp(d) for d in meta['dates']]
            tickers = meta['tickers']
            
            data = {
                'prices': {},
                'features': {},
                'dates': dates,
                'tickers': tickers
            }
            
            # 2. Parquet ë¡œë“œ (ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ì§€ë§Œ, ì—¬ê¸°ì„  ë‹¨ìˆœ ë£¨í”„)
            # í•„ìš”í•œ ê²½ìš° ì—¬ê¸°ì„œ íŠ¹ì • íŒŒì¼ë§Œ ì½ëŠ” 'Lazy Loading' êµ¬í˜„ ê°€ëŠ¥
            for category in ['prices', 'features']:
                target_dir = path / category
                if target_dir.exists():
                    for f in target_dir.glob("*.parquet"):
                        key = f.stem
                        # ì½ì„ ë•Œ ë‹¤ì‹œ float32ë¡œ ë³µì› (ì—°ì‚° ì•ˆì •ì„± ìœ„í•´)
                        df = pd.read_parquet(f).astype('float32')
                        data[category][key] = df
            
            return data

        except Exception as e:
            print(f"   -> Cache corrupted: {e}")
            return None